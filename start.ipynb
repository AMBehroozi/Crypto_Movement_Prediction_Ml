{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d897fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from includes.helpers import get_crypto_data, plot_crypto\n",
    "from includes.technical_indicators import calculate_rsi, calculate_macd, calculate_williams_r, calculate_bollinger_b, calculate_natr, calculate_volume_roc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726df1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = \"2001-01-01\"\n",
    "end = \"2025-12-14\" \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "btc_data = get_crypto_data(\"BTC-USD\", start_date=start, end_date=end)\n",
    "subset = btc_data.tail(200)\n",
    "plot_crypto(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b3867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_data['RSI'] = calculate_rsi(btc_data)\n",
    "\n",
    "# 2. MACD (Returns two columns)\n",
    "btc_data['MACD_Line'], btc_data['Signal_Line'] = calculate_macd(btc_data)\n",
    "\n",
    "# 3. Williams %R\n",
    "btc_data['Williams_R'] = calculate_williams_r(btc_data)\n",
    "\n",
    "# 4. Bollinger %B\n",
    "btc_data['Bollinger_B'] = calculate_bollinger_b(btc_data)\n",
    "\n",
    "# 5. Normalized ATR\n",
    "btc_data['NATR'] = calculate_natr(btc_data)\n",
    "\n",
    "# 6. Volume ROC\n",
    "btc_data['Vol_ROC'] = calculate_volume_roc(btc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c3088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up (drop the first few rows that will be NaN due to lookback periods)\n",
    "btc_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eec96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from includes.helpers import check_indicators\n",
    "check_indicators(btc_data.tail(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17beefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from includes.data_process import create_dataset\n",
    "N_DAYS = 10  # The \"N\" previous days\n",
    "\n",
    "# Generate X and Y\n",
    "X_train, y_train, X_test, y_test, scaler = create_dataset(btc_data, window_size=N_DAYS, scale=True, split_ratio=0.8)\n",
    "\n",
    "print(f\"--- Data Shapes for N={N_DAYS} ---\")\n",
    "print(f\"X_train: {X_train.shape}  (Samples, TimeSteps, Features)\")\n",
    "print(f\"y_train: {y_train.shape}  (Labels)\")\n",
    "print(f\"X_test:  {X_test.shape}\")\n",
    "print(f\"y_test:  {y_test.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--- Example Sample ---\")\n",
    "print(f\"First training sample (Matrix 14x{X_train.shape[2]}):\")\n",
    "# print(X_train[0]) # Uncomment to see the raw numbers\n",
    "print(f\"Target Label: {y_train[0]} (1=Up, 0=Down)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7476c7",
   "metadata": {},
   "source": [
    "# LSTM Model for BTC prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b1e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from includes.ml_models import build_lstm_model\n",
    "from includes.ml_models import train_model\n",
    "from includes.helpers import plot_training_loss\n",
    "from includes.helpers import plot_confusion_matrix_percent\n",
    "from includes.helpers import diagnose_model_output\n",
    "from includes.ml_models import find_optimal_threshold\n",
    "from includes.helpers import save_artifacts\n",
    "\n",
    "# --- Execution Example ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Prepare Input Shape (assuming X_train exists from previous steps)\n",
    "    # Shape: (Samples, TimeSteps, Features)\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    \n",
    "    # 2. Build the Model (using your previous build_lstm_model function)\n",
    "    # You can swap this for any model function (GRU, CNN, etc.)\n",
    "    my_model = build_lstm_model(input_shape)\n",
    "    \n",
    "    # 3. Train using the flexible function\n",
    "    # Try changing use_class_weights to False to see the difference\n",
    "    lstm_history, lstm_model = train_model(\n",
    "        my_model, \n",
    "        X_train, y_train, \n",
    "        X_test, y_test, \n",
    "        epochs=50, \n",
    "        batch_size=32, \n",
    "        use_class_weights=False\n",
    "    )\n",
    "\n",
    "plot_training_loss(lstm_history)\n",
    "\n",
    "plot_confusion_matrix_percent(lstm_model, X_test, y_test )\n",
    "\n",
    "diagnose_model_output(lstm_model, X_test)\n",
    "\n",
    "lstm_optimal_thresh = find_optimal_threshold(lstm_model, X_test, y_test)\n",
    "\n",
    "save_artifacts(lstm_model, scaler, lstm_optimal_thresh, \"btc_lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d5cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from includes.helpers import backtest_strategy\n",
    "\n",
    "test_slice_start = len(btc_data) - len(X_test)\n",
    "df_test_slice = btc_data.iloc[test_slice_start:]\n",
    "backtest_strategy(lstm_model, X_test, df_test_slice, threshold=lstm_optimal_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d46163d",
   "metadata": {},
   "source": [
    "# XGBoost for BTC prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3812832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from includes.ml_models import build_xgboost_model\n",
    "from includes.ml_models import train_model\n",
    "from includes.helpers import plot_training_loss\n",
    "from includes.helpers import plot_confusion_matrix_percent\n",
    "from includes.helpers import diagnose_model_output\n",
    "from includes.ml_models import find_optimal_threshold\n",
    "from includes.helpers import save_artifacts\n",
    "\n",
    "# --- Execution Example ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Prepare Input Shape (assuming X_train exists from previous steps)\n",
    "    # Shape: (Samples, TimeSteps, Features)\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    \n",
    "    # 2. Build the Model (Using the XGBoost Adapter)\n",
    "    # This creates the \"Adapter\" that looks like Keras but runs XGBoost\n",
    "    my_model = build_xgboost_model(input_shape)\n",
    "    \n",
    "    # 3. Train using the flexible function\n",
    "    # Note: For XGBoost, use_class_weights=True is often helpful for imbalanced crypto data\n",
    "    xgb_history, xgb_model = train_model(\n",
    "        my_model, \n",
    "        X_train, y_train, \n",
    "        X_test, y_test, \n",
    "        epochs=100,       # For XGBoost, this maps to n_estimators inside the adapter\n",
    "        batch_size=32,   # Ignored by XGBoost (it uses all data), but required by function signature\n",
    "        use_class_weights=False \n",
    "    )\n",
    "\n",
    "    # 4. Visualization & Diagnostics\n",
    "    # Plot LogLoss curve (simulating Keras \"Loss\")\n",
    "    plot_training_loss(xgb_history)\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plot_confusion_matrix_percent(xgb_model, X_test, y_test)\n",
    "\n",
    "    # Check Confidence Histogram\n",
    "    diagnose_model_output(xgb_model, X_test)\n",
    "\n",
    "    # 5. Optimize & Save\n",
    "    # Find the best threshold for this specific model\n",
    "    xgb_optimal_thresh = find_optimal_threshold(xgb_model, X_test, y_test)\n",
    "\n",
    "    # Save Artifacts\n",
    "    # The Adapter automatically saves as .json instead of .keras\n",
    "    save_artifacts(xgb_model, scaler, xgb_optimal_thresh, \"btc_xgboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de853de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from includes.helpers import backtest_strategy\n",
    "\n",
    "test_slice_start = len(btc_data) - len(X_test)\n",
    "df_test_slice = btc_data.iloc[test_slice_start:]\n",
    "backtest_strategy(xgb_model, X_test, df_test_slice, threshold=xgb_optimal_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb149d54",
   "metadata": {},
   "source": [
    "# Random Forest fot BTC prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3b1390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from includes.ml_models import build_rf_model\n",
    "from includes.ml_models import train_model, find_optimal_threshold\n",
    "from includes.helpers import (plot_training_loss, \n",
    "                              plot_confusion_matrix_percent, \n",
    "                              diagnose_model_output, \n",
    "                              save_artifacts)\n",
    "\n",
    "# --- Execution Block ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- 1. Initializing Random Forest Strategy ---\")\n",
    "    \n",
    "    # 1. Prepare Input Shape\n",
    "    # Shape: (Samples, TimeSteps, Features) -> e.g., (1000, 14, 8)\n",
    "    # The RF Adapter will flatten this internally to (1000, 112)\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    \n",
    "    # 2. Build the Model\n",
    "    # We use the 'Adapter' so it works with our existing training pipeline\n",
    "    my_model = build_rf_model(input_shape)\n",
    "    \n",
    "    # 3. Train the Model\n",
    "    # NOTE: 'epochs' and 'batch_size' are placeholders here.\n",
    "    # Random Forest trains in one shot (no epochs), but we pass the values\n",
    "    # to keep the function signature compatible with the LSTM code.\n",
    "    print(\"\\n--- 2. Starting Training (One-Shot) ---\")\n",
    "    rf_history, rf_model = train_model(\n",
    "        my_model, \n",
    "        X_train, y_train, \n",
    "        X_test, y_test, \n",
    "        epochs=50,        # Placeholder (RF doesn't iterate)\n",
    "        batch_size=32,   # Placeholder (RF uses all data)\n",
    "        use_class_weights=True # Critical for imbalanced market data\n",
    "    )\n",
    "\n",
    "    # 4. Diagnostics & Visualization\n",
    "    print(\"\\n--- 3. Evaluating Performance ---\")\n",
    "    \n",
    "\n",
    "    # B. Confusion Matrix (Did we catch the 'Up' moves?)\n",
    "    plot_confusion_matrix_percent(rf_model, X_test, y_test)\n",
    "\n",
    "    # C. Confidence Check (Are predictions bunched in the middle?)\n",
    "    diagnose_model_output(rf_model, X_test)\n",
    "\n",
    "    # 5. Optimization\n",
    "    # We find the exact probability threshold (e.g., 0.52) that maximizes accuracy\n",
    "    print(\"\\n--- 4. Optimizing Threshold ---\")\n",
    "    rf_optimal_thresh = find_optimal_threshold(rf_model, X_test, y_test)\n",
    "\n",
    "    # 6. Save Artifacts\n",
    "    # This automatically saves the model as a .pkl file because it detects it's Sklearn\n",
    "    print(f\"\\n--- 5. Saving System (Threshold: {rf_optimal_thresh:.4f}) ---\")\n",
    "    save_artifacts(rf_model, scaler, rf_optimal_thresh, \"btc_rf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5147b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from includes.helpers import backtest_strategy\n",
    "\n",
    "test_slice_start = len(btc_data) - len(X_test)\n",
    "df_test_slice = btc_data.iloc[test_slice_start:]\n",
    "backtest_strategy(rf_model, X_test, df_test_slice, threshold=rf_optimal_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2fa4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from includes.ml_models import build_svm_model\n",
    "from includes.ml_models import find_optimal_threshold\n",
    "from includes.helpers import (plot_confusion_matrix_percent, \n",
    "                              diagnose_model_output, \n",
    "                              save_artifacts)\n",
    "\n",
    "# --- 1. REDEFINE TRAIN_MODEL (Safety Copy) ---\n",
    "def train_model(model, X_train, y_train, X_test, y_test, epochs=50, batch_size=32, use_class_weights=True):\n",
    "    from sklearn.utils import class_weight \n",
    "    weights_dict = None\n",
    "    if use_class_weights:\n",
    "        cw = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "        weights_dict = {i: cw[i] for i in range(len(cw))}\n",
    "        print(f\"--- Computed Class Weights ---\\n{weights_dict}\")\n",
    "\n",
    "    if hasattr(model, 'compile'): \n",
    "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, \n",
    "                            class_weight=weights_dict, validation_data=(X_test, y_test), verbose=1)\n",
    "    else: \n",
    "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, \n",
    "                            class_weight=weights_dict, validation_data=(X_test, y_test), verbose=1)\n",
    "    \n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"\\nFinal Test Accuracy: {accuracy*100:.2f}%\")\n",
    "    return history, model\n",
    "\n",
    "\n",
    "# --- 2. EXECUTE SVM TRAINING ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- 1. Initializing SVM Strategy ---\")\n",
    "    \n",
    "    # 1. Prepare Input\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    \n",
    "    # 2. Build Model\n",
    "    my_model = build_svm_model(input_shape)\n",
    "    \n",
    "    # 3. Train\n",
    "    # Note: SVM training time grows with data size. For <5000 rows it is fast.\n",
    "    print(\"\\n--- 2. Starting Training ---\")\n",
    "    svm_history, svm_model = train_model(\n",
    "            my_model, \n",
    "            X_train, y_train, \n",
    "            X_test, y_test, \n",
    "            epochs=1,       # Placeholder (Ignored)\n",
    "            batch_size=32,  # Placeholder (Ignored)\n",
    "            use_class_weights=True \n",
    "        )\n",
    "    \n",
    "    # 4. Diagnostics\n",
    "    print(\"\\n--- 3. Evaluating Performance ---\")\n",
    "    plot_confusion_matrix_percent(svm_model, X_test, y_test)\n",
    "    diagnose_model_output(svm_model, X_test)\n",
    "\n",
    "    # 5. Optimize & Save\n",
    "    print(\"\\n--- 4. Optimizing Threshold ---\")\n",
    "    svm_optimal_thresh = find_optimal_threshold(svm_model, X_test, y_test)\n",
    "\n",
    "    print(f\"\\n--- 5. Saving System (Threshold: {svm_optimal_thresh:.4f}) ---\")\n",
    "    # Prefix: 'btc_svm'\n",
    "    save_artifacts(svm_model, scaler, svm_optimal_thresh, \"btc_svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eedabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from includes.helpers import backtest_strategy\n",
    "\n",
    "test_slice_start = len(btc_data) - len(X_test)\n",
    "df_test_slice = btc_data.iloc[test_slice_start:]\n",
    "backtest_strategy(svm_model, X_test, df_test_slice, threshold=svm_optimal_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef4b7d",
   "metadata": {},
   "source": [
    "# K nearest neighbors for BTC prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fecfcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from includes.ml_models import *\n",
    "from includes.ml_models import train_model, find_optimal_threshold\n",
    "from includes.helpers import (plot_confusion_matrix_percent, \n",
    "                              diagnose_model_output, \n",
    "                              save_artifacts)\n",
    "\n",
    "# --- EXECUTE KNN TRAINING ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- 1. Initializing KNN (Pattern Matching) Strategy ---\")\n",
    "    \n",
    "    # 1. Prepare Input\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    \n",
    "    # 2. Build Model\n",
    "    my_model = build_knn_model(input_shape)\n",
    "    \n",
    "    # 3. Train\n",
    "    print(\"\\n--- 2. Starting Training ---\")\n",
    "    # Note: KNN 'training' is just indexing the data. It is instant.\n",
    "    knn_history, knn_model = train_model(\n",
    "        my_model, \n",
    "        X_train, y_train, \n",
    "        X_test, y_test, \n",
    "        epochs=1,       # Ignored\n",
    "        batch_size=32,  # Ignored\n",
    "        use_class_weights=False # Handled internally by 'weights=distance'\n",
    "    )\n",
    "\n",
    "    # 4. Diagnostics\n",
    "    print(\"\\n--- 3. Evaluating Performance ---\")\n",
    "    \n",
    "    # Plot Confusion Matrix\n",
    "    plot_confusion_matrix_percent(knn_model, X_test, y_test)\n",
    "\n",
    "    # Check Confidence\n",
    "    diagnose_model_output(knn_model, X_test)\n",
    "\n",
    "    # 5. Optimize & Save\n",
    "    print(\"\\n--- 4. Optimizing Threshold ---\")\n",
    "    knn_optimal_thresh = find_optimal_threshold(knn_model, X_test, y_test)\n",
    "\n",
    "    print(f\"\\n--- 5. Saving System (Threshold: {knn_optimal_thresh:.4f}) ---\")\n",
    "    save_artifacts(knn_model, scaler, knn_optimal_thresh, \"btc_knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965f9f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from includes.helpers import backtest_strategy\n",
    "\n",
    "test_slice_start = len(btc_data) - len(X_test)\n",
    "knn_test_slice = btc_data.iloc[test_slice_start:]\n",
    "backtest_strategy(knn_model, X_test, knn_test_slice, threshold=knn_optimal_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479a6443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def backtest_models_individually(models_config, X_test, df_test, initial_capital=1000):\n",
    "    \"\"\"\n",
    "    Backtests multiple models individually and compares them against Buy & Hold.\n",
    "    NO ENSEMBLE logic included.\n",
    "    \n",
    "    Args:\n",
    "        models_config (list of dicts): \n",
    "            [\n",
    "              {'model': xgb_model,  'threshold': 0.48, 'name': 'XGBoost'},\n",
    "              ...\n",
    "            ]\n",
    "        X_test (np.array): The 3D feature set used for prediction.\n",
    "        df_test (pd.DataFrame): The original Dataframe matching X_test (must have 'Close').\n",
    "        initial_capital (float): Starting cash.\n",
    "    \"\"\"\n",
    "    print(f\"--- ðŸš€ STARTING INDIVIDUAL MODEL BACKTEST ---\")\n",
    "    \n",
    "    # 1. Align Prices\n",
    "    prices = df_test['Close'].values\n",
    "    \n",
    "    # Safety check for length mismatch\n",
    "    if len(prices) != len(X_test):\n",
    "        print(f\"âš ï¸ Warning: Length mismatch. Prices: {len(prices)}, X_test: {len(X_test)}\")\n",
    "        min_len = min(len(prices), len(X_test))\n",
    "        prices = prices[:min_len]\n",
    "        X_test = X_test[:min_len]\n",
    "\n",
    "    equity_curves = {}\n",
    "    \n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    # --- 2. LOOP THROUGH EACH MODEL ---\n",
    "    for config in models_config:\n",
    "        model = config['model']\n",
    "        thresh = config['threshold']\n",
    "        name = config['name']\n",
    "        \n",
    "        # A. Get Probabilities (Handle Keras vs Sklearn Adapters)\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            # Adapters (XGB, RF, SVM, KNN) -> predict_proba -> [class_0, class_1]\n",
    "            probs = model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            # Keras (LSTM) -> predict -> [prob]\n",
    "            probs = model.predict(X_test, verbose=0).flatten()\n",
    "            \n",
    "        # B. Calculate Individual Equity Curve\n",
    "        signals = (probs > thresh).astype(int)\n",
    "        curve = _run_simulation(signals, prices, initial_capital)\n",
    "        equity_curves[name] = curve\n",
    "        \n",
    "        # Plot Individual Model (Solid lines for better visibility)\n",
    "        plt.plot(curve, label=f\"{name} (${curve[-1]:.0f})\", linewidth=1.5)\n",
    "        print(f\"Finished {name}: Final Value ${curve[-1]:.2f}\")\n",
    "\n",
    "    # --- 3. BENCHMARK (BUY & HOLD) ---\n",
    "    btc_return = (prices[-1] - prices[0]) / prices[0]\n",
    "    buy_hold_final = initial_capital * (1 + btc_return)\n",
    "    \n",
    "    # Create a straight line for Buy & Hold visual\n",
    "    plt.plot([0, len(prices)], [initial_capital, buy_hold_final], \n",
    "             label=f\"Buy & Hold (${buy_hold_final:.0f})\", color='green', linestyle='--', linewidth=2.5)\n",
    "\n",
    "    # --- 4. FINALIZE PLOT ---\n",
    "    plt.title(f'Comparative Backtest: Models vs Market (Start: ${initial_capital})', fontsize=14)\n",
    "    plt.ylabel('Portfolio Value ($)')\n",
    "    plt.xlabel('Trading Days')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print Summary Table\n",
    "    print(f\"\\n{'STRATEGY':<15} | {'FINAL VALUE':<12} | {'RETURN':<8}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    sorted_results = sorted(equity_curves.items(), key=lambda x: x[1][-1], reverse=True)\n",
    "    \n",
    "    for name, curve in sorted_results:\n",
    "        final_val = curve[-1]\n",
    "        ret = ((final_val - initial_capital) / initial_capital) * 100\n",
    "        print(f\"{name:<15} | ${final_val:,.2f}   | {ret:+.2f}%\")\n",
    "        \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"{'Buy & Hold':<15} | ${buy_hold_final:,.2f}   | {btc_return*100:+.2f}%\")\n",
    "\n",
    "\n",
    "def _run_simulation(signals, prices, initial_capital):\n",
    "    \"\"\"Helper to run the cash/position loop.\"\"\"\n",
    "    cash = initial_capital\n",
    "    position = 0\n",
    "    curve = []\n",
    "    \n",
    "    for i in range(len(signals) - 1):\n",
    "        price_today = prices[i]\n",
    "        \n",
    "        if signals[i] == 1 and position == 0:\n",
    "            # BUY\n",
    "            position = cash / price_today\n",
    "            cash = 0\n",
    "        elif signals[i] == 0 and position > 0:\n",
    "            # SELL\n",
    "            cash = position * price_today\n",
    "            position = 0\n",
    "            \n",
    "        # Daily Mark-to-Market\n",
    "        val = cash + (position * price_today)\n",
    "        curve.append(val)\n",
    "        \n",
    "    # Append final day\n",
    "    val = cash + (position * prices[-1])\n",
    "    curve.append(val)\n",
    "    return curve\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION EXAMPLE\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Define your lineup\n",
    "    models_to_test = [\n",
    "        # {'model': lstm_model, 'threshold': optimal_thresh,      'name': 'LSTM'}, # Uncomment if LSTM is in memory\n",
    "        {'model': xgb_model,   'threshold': xgb_optimal_thresh, 'name': 'XGBoost'},\n",
    "        {'model': rf_model,    'threshold': rf_optimal_thresh,  'name': 'RandomForest'},\n",
    "        {'model': svm_model,   'threshold': svm_optimal_thresh, 'name': 'SVM'},\n",
    "        {'model': knn_model,   'threshold': knn_optimal_thresh, 'name': 'KNN'}\n",
    "    ]\n",
    "    \n",
    "    # 2. Prepare the Test Slice\n",
    "    test_slice_start = len(btc_data) - len(X_test)\n",
    "    df_test_slice = btc_data.iloc[test_slice_start:]\n",
    "    \n",
    "    # 3. Run\n",
    "    backtest_models_individually(models_to_test, X_test, df_test_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f238ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "\n",
    "def rolling_window_backtest(models_config, X_test, df_test, \n",
    "                            window_days=60, n_starts=20, initial_capital=1000):\n",
    "    \"\"\"\n",
    "    Runs N separate backtests starting from random days.\n",
    "    \"\"\"\n",
    "    print(f\"--- ðŸŽ² STARTING ROLLING BACKTEST ({n_starts} Random Windows) ---\")\n",
    "    \n",
    "    # 1. Align Prices & Dates\n",
    "    prices = df_test['Close'].values\n",
    "    dates = df_test.index\n",
    "    \n",
    "    if len(prices) != len(X_test):\n",
    "        min_len = min(len(prices), len(X_test))\n",
    "        prices = prices[:min_len]\n",
    "        X_test = X_test[:min_len]\n",
    "        dates = dates[:min_len]\n",
    "\n",
    "    # 2. Pre-calculate Signals (Speed Optimization)\n",
    "    model_signals = {}\n",
    "    for config in models_config:\n",
    "        model = config['model']\n",
    "        thresh = config['threshold']\n",
    "        \n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            probs = model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            probs = model.predict(X_test, verbose=0).flatten()\n",
    "            \n",
    "        model_signals[config['name']] = (probs > thresh).astype(int)\n",
    "\n",
    "    # 3. Select Random Start Dates\n",
    "    # We remove the fixed seed so it is different every time you run it\n",
    "    # np.random.seed(42) <--- COMMENTED OUT FOR TRUE RANDOMNESS\n",
    "    \n",
    "    max_start_index = len(prices) - window_days\n",
    "    if max_start_index < 1:\n",
    "        raise ValueError(\"Not enough test data for this window size!\")\n",
    "\n",
    "    # Pick N random indices\n",
    "    start_indices = np.random.choice(range(max_start_index), n_starts, replace=False)\n",
    "    \n",
    "    # Print the dates so you can see them\n",
    "    print(\"\\nðŸ“… Random Start Dates Selected:\")\n",
    "    selected_dates = [dates[i].strftime('%Y-%m-%d') for i in start_indices[:5]]\n",
    "    print(f\"   {selected_dates} ... and {n_starts - 5} more.\")\n",
    "\n",
    "    # 4. Run Simulations\n",
    "    results_data = {config['name']: [] for config in models_config}\n",
    "    results_data['Buy & Hold'] = []\n",
    "\n",
    "    for start_idx in start_indices:\n",
    "        end_idx = start_idx + window_days\n",
    "        \n",
    "        # Slicing for this specific window\n",
    "        window_prices = prices[start_idx : end_idx]\n",
    "        \n",
    "        # Benchmark Return\n",
    "        bh_return = ((window_prices[-1] - window_prices[0]) / window_prices[0]) * 100\n",
    "        results_data['Buy & Hold'].append(bh_return)\n",
    "        \n",
    "        # Model Returns\n",
    "        for config in models_config:\n",
    "            name = config['name']\n",
    "            window_signals = model_signals[name][start_idx : end_idx]\n",
    "            \n",
    "            final_val = _run_simulation_fast(window_signals, window_prices, initial_capital)\n",
    "            roi = ((final_val - initial_capital) / initial_capital) * 100\n",
    "            results_data[name].append(roi)\n",
    "\n",
    "    # 5. Visualization (Box Plot)\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plot_df = pd.DataFrame(results_data)\n",
    "    \n",
    "    sns.boxplot(data=plot_df, palette=\"viridis\")\n",
    "    plt.axhline(0, color='red', linestyle='--', alpha=0.5, label=\"Breakeven\")\n",
    "    \n",
    "    plt.title(f'Robustness Check: Return Distribution ({n_starts} Random {window_days}-Day Windows)', fontsize=14)\n",
    "    plt.ylabel('Return on Investment (%)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # 6. Summary Statistics\n",
    "    print(f\"\\n{'STRATEGY':<15} | {'WIN RATE':<10} | {'MEDIAN ROI':<12} | {'RISK (StdDev)':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    bh_returns = np.array(results_data['Buy & Hold'])\n",
    "    \n",
    "    for name in models_config:\n",
    "        name_str = name['name']\n",
    "        model_returns = np.array(results_data[name_str])\n",
    "        \n",
    "        # Win Rate: How often did we beat Buy & Hold?\n",
    "        wins = np.sum(model_returns > bh_returns)\n",
    "        win_rate = (wins / n_starts) * 100\n",
    "        \n",
    "        median_roi = np.median(model_returns)\n",
    "        std_dev = np.std(model_returns)\n",
    "        \n",
    "        print(f\"{name_str:<15} | {win_rate:5.1f}%     | {median_roi:6.2f}%      | {std_dev:6.2f}\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Buy & Hold':<15} | {'N/A':<10} | {np.median(bh_returns):6.2f}%      | {np.std(bh_returns):6.2f}\")\n",
    "\n",
    "\n",
    "def _run_simulation_fast(signals, prices, initial_capital):\n",
    "    cash = initial_capital\n",
    "    position = 0\n",
    "    for i in range(len(signals) - 1):\n",
    "        if signals[i] == 1 and position == 0:\n",
    "            position = cash / prices[i]; cash = 0\n",
    "        elif signals[i] == 0 and position > 0:\n",
    "            cash = position * prices[i]; position = 0\n",
    "    return cash + (position * prices[-1])\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Define models\n",
    "    models_to_test = [\n",
    "        {'model': xgb_model,   'threshold': xgb_optimal_thresh, 'name': 'XGBoost'},\n",
    "        {'model': rf_model,    'threshold': rf_optimal_thresh,  'name': 'RandomForest'},\n",
    "        {'model': svm_model,   'threshold': svm_optimal_thresh, 'name': 'SVM'},\n",
    "        {'model': knn_model,   'threshold': knn_optimal_thresh, 'name': 'KNN'}\n",
    "    ]\n",
    "    \n",
    "    # Prepare Slice\n",
    "    test_slice_start = len(btc_data) - len(X_test)\n",
    "    df_test_slice = btc_data.iloc[test_slice_start:]\n",
    "    \n",
    "    # Run Test: 50 random starts, 90-day duration each\n",
    "    rolling_window_backtest(models_to_test, X_test, df_test_slice, \n",
    "                            window_days=30, n_starts=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
