{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f180e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 14:47:39.499395: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from xgboost import XGBClassifier # Needed for loading XGBoost\n",
    "from includes.technical_indicators import calculate_rsi, calculate_macd, calculate_williams_r, calculate_bollinger_b, calculate_natr, calculate_volume_roc\n",
    "\n",
    "class CryptoPredictor:\n",
    "    def __init__(self, prefix=\"btc_lstm\"):\n",
    "        self.prefix = prefix\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.threshold = 0.5\n",
    "        self.window_size = 7 # Must match your training window (e.g., 7 or 14)\n",
    "        self.model_type = \"keras\" # Default, will be detected in load_artifacts\n",
    "        \n",
    "    def load_artifacts(self):\n",
    "        \"\"\"Smart loader: Detects if model is Keras, XGBoost, or Pickle.\"\"\"\n",
    "        print(f\"Loading system for prefix: {self.prefix}...\")\n",
    "        \n",
    "        # 1. Define Paths\n",
    "        folder = \"saved_artifacts\"\n",
    "        path_keras = f\"{folder}/{self.prefix}_model.keras\" # LSTM\n",
    "        path_json  = f\"{folder}/{self.prefix}_model.json\"  # XGBoost\n",
    "        path_pkl   = f\"{folder}/{self.prefix}_model.pkl\"   # Random Forest\n",
    "        \n",
    "        # 2. Detect and Load Model\n",
    "        if os.path.exists(path_keras):\n",
    "            print(f\"Detected Keras model: {path_keras}\")\n",
    "            self.model = tf.keras.models.load_model(path_keras)\n",
    "            self.model_type = \"keras\"\n",
    "            \n",
    "        elif os.path.exists(path_json):\n",
    "            print(f\"Detected XGBoost model: {path_json}\")\n",
    "            self.model = XGBClassifier()\n",
    "            self.model.load_model(path_json)\n",
    "            self.model_type = \"xgboost\"\n",
    "            \n",
    "        elif os.path.exists(path_pkl):\n",
    "            print(f\"Detected Pickle model (RF/Sklearn): {path_pkl}\")\n",
    "            with open(path_pkl, \"rb\") as f:\n",
    "                self.model = pickle.load(f)\n",
    "            self.model_type = \"sklearn\"\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"No model found for prefix '{self.prefix}' in '{folder}/'. Checked .keras, .json, and .pkl\")\n",
    "\n",
    "        # 3. Load Scaler\n",
    "        with open(f\"{folder}/{self.prefix}_scaler.pkl\", \"rb\") as f:\n",
    "            self.scaler = pickle.load(f)\n",
    "            \n",
    "        # 4. Load Config\n",
    "        with open(f\"{folder}/{self.prefix}_config.json\", \"r\") as f:\n",
    "            config = json.load(f)\n",
    "            self.threshold = config[\"optimal_threshold\"]\n",
    "            \n",
    "        print(f\"System loaded. Type: {self.model_type}. Threshold: {self.threshold:.4f}\")\n",
    "\n",
    "    def fetch_recent_data(self, ticker=\"BTC-USD\", target_date_str=None):\n",
    "        \"\"\"\n",
    "        Fetches data directly from Yahoo API.\n",
    "        \"\"\"\n",
    "        # 1. Calculate Time Window\n",
    "        if target_date_str:\n",
    "            target_dt = datetime.strptime(target_date_str, \"%Y-%m-%d\")\n",
    "        else:\n",
    "            target_dt = datetime.now()\n",
    "\n",
    "        # Set END time to 23:59:59 of the target date\n",
    "        end_dt = target_dt.replace(hour=23, minute=59, second=59)\n",
    "        period2 = int(end_dt.timestamp())\n",
    "        \n",
    "        # Set START time to 180 days before that\n",
    "        start_dt = end_dt - timedelta(days=180)\n",
    "        period1 = int(start_dt.timestamp())\n",
    "\n",
    "        print(f\"Fetching {ticker} data ending on {target_dt.strftime('%Y-%m-%d')}...\")\n",
    "        \n",
    "        # 2. Define API Endpoint\n",
    "        url = f\"https://query1.finance.yahoo.com/v8/finance/chart/{ticker}\"\n",
    "        params = {\n",
    "            \"period1\": period1,\n",
    "            \"period2\": period2,\n",
    "            \"interval\": \"1d\",\n",
    "            \"events\": \"div,split\"\n",
    "        }\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "        # 3. Perform Request\n",
    "        try:\n",
    "            response = requests.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            result = data['chart']['result'][0]\n",
    "            timestamps = result['timestamp']\n",
    "            quote = result['indicators']['quote'][0]\n",
    "            \n",
    "            df = pd.DataFrame({\n",
    "                'Date': pd.to_datetime(timestamps, unit='s'),\n",
    "                'Open': quote['open'],\n",
    "                'High': quote['high'],\n",
    "                'Low': quote['low'],\n",
    "                'Close': quote['close'],\n",
    "                'Volume': quote['volume']\n",
    "            })\n",
    "            df.set_index('Date', inplace=True)\n",
    "            df = df.dropna()\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"API Error: {e}\")\n",
    "\n",
    "        if df.empty:\n",
    "            raise ValueError(\"API returned empty data.\")\n",
    "            \n",
    "        return df\n",
    "\n",
    "    def preprocess_live_data(self, df):\n",
    "        \"\"\"Calculates indicators, scales, and reshapes data based on model type.\"\"\"\n",
    "        # 1. Calculate Indicators\n",
    "        df['RSI'] = calculate_rsi(df)\n",
    "        df['MACD_Line'], df['Signal_Line'] = calculate_macd(df)\n",
    "        df['Williams_R'] = calculate_williams_r(df)\n",
    "        df['Bollinger_B'] = calculate_bollinger_b(df)\n",
    "        df['NATR'] = calculate_natr(df)\n",
    "        df['Vol_ROC'] = calculate_volume_roc(df)\n",
    "        \n",
    "        # 2. Drop NaNs\n",
    "        df = df.dropna()\n",
    "        \n",
    "        # 3. Select Features\n",
    "        feature_cols = ['Close', 'RSI', 'MACD_Line', 'Signal_Line', \n",
    "                        'Williams_R', 'Bollinger_B', 'NATR', 'Vol_ROC']\n",
    "        \n",
    "        # 4. Get the LAST Window\n",
    "        last_window = df[feature_cols].tail(self.window_size).values\n",
    "        \n",
    "        if len(last_window) < self.window_size:\n",
    "            raise ValueError(f\"Not enough data. Needed {self.window_size}, got {len(last_window)}.\")\n",
    "            \n",
    "        # 5. Scale\n",
    "        scaled_window = self.scaler.transform(last_window)\n",
    "        \n",
    "        # 6. Reshape based on Model Type\n",
    "        # LSTM wants 3D: (1, 14, 8)\n",
    "        # XGBoost/RF want 2D: (1, 112) [Flattened]\n",
    "        if self.model_type == \"keras\":\n",
    "            final_input = np.expand_dims(scaled_window, axis=0)\n",
    "        else:\n",
    "            final_input = scaled_window.flatten().reshape(1, -1)\n",
    "        \n",
    "        last_date = df.index[-1]\n",
    "        last_price = df['Close'].iloc[-1]\n",
    "        \n",
    "        return final_input, last_price, last_date\n",
    "\n",
    "    def predict_next_day(self, date_str=None):\n",
    "        \"\"\"\n",
    "        Main execution method with Probability & Confidence reporting.\n",
    "        \"\"\"\n",
    "        # 1. Get Data\n",
    "        df = self.fetch_recent_data(target_date_str=date_str)\n",
    "        \n",
    "        # 2. Process\n",
    "        X_input, current_price, data_date = self.preprocess_live_data(df)\n",
    "        \n",
    "        # 3. Get Probability (Universal Logic)\n",
    "        if self.model_type == \"keras\":\n",
    "            # Keras returns [[0.45]]\n",
    "            prob = self.model.predict(X_input, verbose=0)[0][0]\n",
    "        else:\n",
    "            # XGBoost/Sklearn return [[0.55, 0.45]] (Class 0, Class 1)\n",
    "            # We want the probability of Class 1 (Up)\n",
    "            prob = self.model.predict_proba(X_input)[0][1]\n",
    "        \n",
    "        # 4. Apply Optimum Threshold\n",
    "        prediction = 1 if prob > self.threshold else 0\n",
    "        direction = \"UP ðŸŸ¢\" if prediction == 1 else \"DOWN ðŸ”´\"\n",
    "        \n",
    "        # 5. Calculate Confidence\n",
    "        distance = abs(prob - self.threshold)\n",
    "        \n",
    "        if distance < 0.02:\n",
    "            confidence = \"Very Low (Risky)\"\n",
    "        elif distance < 0.05:\n",
    "            confidence = \"Low\"\n",
    "        elif distance < 0.10:\n",
    "            confidence = \"Medium\"\n",
    "        else:\n",
    "            confidence = \"High ðŸ”¥\"\n",
    "\n",
    "        # 6. Report\n",
    "        print(f\"\\n--- PREDICTION REPORT ---\")\n",
    "        print(f\"Data Date:       {data_date.strftime('%Y-%m-%d')}\")\n",
    "        print(f\"Input Price:     ${current_price:,.2f} (Reference Level)\")\n",
    "        print(f\"---------------------------\")\n",
    "        print(f\"Probability (Up): {prob*100:.2f}%\")\n",
    "        print(f\"Threshold Used:   {self.threshold*100:.2f}%\")\n",
    "        print(f\"Margin:           {distance*100:.2f}% pts\")\n",
    "        print(f\"---------------------------\")\n",
    "        print(f\"Prediction:       {direction}\")\n",
    "        print(f\"Confidence:       {confidence}\")\n",
    "        \n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af5d9c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading system for prefix: btc_knn...\n",
      "Detected Pickle model (RF/Sklearn): saved_artifacts/btc_knn_model.pkl\n",
      "System loaded. Type: sklearn. Threshold: 0.4800\n",
      "Fetching BTC-USD data ending on 2025-12-15...\n",
      "\n",
      "--- PREDICTION REPORT ---\n",
      "Data Date:       2025-12-15\n",
      "Input Price:     $86,206.04 (Reference Level)\n",
      "---------------------------\n",
      "Probability (Up): 40.66%\n",
      "Threshold Used:   48.00%\n",
      "Margin:           7.34% pts\n",
      "---------------------------\n",
      "Prediction:       DOWN ðŸ”´\n",
      "Confidence:       Medium\n"
     ]
    }
   ],
   "source": [
    "# --- Usage Example ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure you use the correct prefix for the model you trained!\n",
    "    # Examples: \"btc_lstm\", \"btc_xgboost\", \"btc_rf, btc_svm, btc_knn\"\n",
    "    bot = CryptoPredictor(prefix=\"btc_knn\") \n",
    "    \n",
    "    bot.load_artifacts()\n",
    "    bot.predict_next_day()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
